{"cells":[{"cell_type":"markdown","id":"a00e032c","metadata":{"id":"a00e032c"},"source":["***Important*** DO NOT CLEAR THE OUTPUT OF THIS NOTEBOOK AFTER EXECUTION!!!"]},{"cell_type":"code","execution_count":1,"id":"5ac36d3a","metadata":{"id":"5ac36d3a","nbgrader":{"grade":false,"grade_id":"cell-Worker_Count","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"cf88b954-f39a-412a-d87e-660833e735b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["NAME          PLATFORM  WORKER_COUNT  PREEMPTIBLE_WORKER_COUNT  STATUS   ZONE           SCHEDULED_DELETE\r\n","cluster-8605  GCE       4                                       RUNNING  us-central1-a\r\n"]}],"source":["# if the following command generates an error, you probably didn't enable \n","# the cluster security option \"Allow API access to all Google Cloud services\"\n","# under Manage Security â†’ Project Access when setting up the cluster\n","!gcloud dataproc clusters list --region us-central1"]},{"cell_type":"code","execution_count":2,"id":"bf199e6a","metadata":{"id":"bf199e6a","nbgrader":{"grade":false,"grade_id":"cell-Setup","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"fc0e315d-21e9-411d-d69c-5b97e4e5d629"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m"]}],"source":["!pip install -q google-cloud-storage==1.43.0\n","!pip install -q graphframes"]},{"cell_type":"code","execution_count":3,"id":"d8f56ecd","metadata":{"id":"d8f56ecd","nbgrader":{"grade":false,"grade_id":"cell-Imports","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"a24aa24b-aa75-4823-83ca-1d7deef0f0de"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import pyspark\n","import sys\n","from collections import Counter, OrderedDict, defaultdict\n","import itertools\n","from itertools import islice, count, groupby\n","import pandas as pd\n","import os\n","import re\n","from operator import itemgetter\n","import nltk\n","from nltk.stem.porter import *\n","from nltk.corpus import stopwords\n","from time import time\n","from pathlib import Path\n","import pickle\n","import numpy as np\n","from google.cloud import storage\n","\n","import hashlib\n","def _hash(s):\n","    return hashlib.blake2b(bytes(s, encoding='utf8'), digest_size=5).hexdigest()\n","\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":4,"id":"38a897f2","metadata":{"id":"38a897f2","nbgrader":{"grade":false,"grade_id":"cell-jar","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"8f93a7ec-71e0-49c1-fc81-9af385849a90"},"outputs":[{"name":"stdout","output_type":"stream","text":["-rw-r--r-- 1 root root 247882 Dec 28 10:09 /usr/lib/spark/jars/graphframes-0.8.2-spark3.1-s_2.12.jar\r\n"]}],"source":["# if nothing prints here you forgot to include the initialization script when starting the cluster\n","!ls -l /usr/lib/spark/jars/graph*"]},{"cell_type":"code","execution_count":5,"id":"47900073","metadata":{"id":"47900073","nbgrader":{"grade":false,"grade_id":"cell-pyspark-import","locked":true,"schema_version":3,"solution":false,"task":false}},"outputs":[],"source":["from pyspark.sql import *\n","from pyspark.sql.functions import *\n","from pyspark import SparkContext, SparkConf, SparkFiles\n","from pyspark.sql import SQLContext\n","from graphframes import *"]},{"cell_type":"code","execution_count":6,"id":"72bed56b","metadata":{"id":"72bed56b","nbgrader":{"grade":false,"grade_id":"cell-spark-version","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"07b4e22b-a252-42fb-fe46-d9050e4e7ca8","scrolled":true},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://cluster-8605-m.c.finalprojectyuvalandnoam.internal:33799\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.3</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f0cadda6520>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"code","execution_count":7,"id":"980e62a5","metadata":{"id":"980e62a5","nbgrader":{"grade":false,"grade_id":"cell-bucket_name","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["# Put your bucket name below and make sure you can access it without an error\n","bucket_name = 'bucket_wiki1' \n","full_path = f\"gs://{bucket_name}/\"\n","paths=[]\n","\n","client = storage.Client()\n","blobs = client.list_blobs(bucket_name)\n","for b in blobs:\n","    if b.name != 'graphframes.sh':\n","        paths.append(full_path+b.name)"]},{"cell_type":"markdown","id":"582c3f5e","metadata":{"id":"582c3f5e"},"source":["# Building an inverted index"]},{"cell_type":"markdown","id":"481f2044","metadata":{"id":"481f2044"},"source":["Here, we read the entire corpus to an rdd, directly from Google Storage Bucket and use your code from Colab to construct an inverted index."]},{"cell_type":"code","execution_count":8,"id":"e4c523e7","metadata":{"id":"e4c523e7","outputId":"22251c5b-37e6-4632-8776-efee2625495f","scrolled":false},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["parquetFile = spark.read.parquet(*paths)\n","doc_text_pairs_title = parquetFile.select(\"title\", \"id\").rdd\n","doc_text_pairs_anchor = parquetFile.select(\"anchor_text\", \"id\").rdd\n","doc_text_pairs_body = parquetFile.select(\"text\", \"id\").rdd\n"]},{"cell_type":"code","execution_count":9,"id":"121fe102","metadata":{"id":"121fe102","outputId":"327fe81b-80f4-4b3a-8894-e74720d92e35"},"outputs":[{"name":"stdout","output_type":"stream","text":["inverted_index_gcp.py\r\n"]}],"source":["# if nothing prints here you forgot to upload the file inverted_index_gcp.py to the home dir\n","%cd -q /home/dataproc\n","!ls inverted_index_gcp.py"]},{"cell_type":"code","execution_count":10,"id":"57c101a8","metadata":{"id":"57c101a8","outputId":"e55432dc-0f76-4a89-b584-a6aa2f78e12f","scrolled":true},"outputs":[],"source":["# adding our python module to the cluster\n","sc.addFile(\"/home/dataproc/inverted_index_gcp.py\")\n","sys.path.insert(0,SparkFiles.getRootDirectory())"]},{"cell_type":"code","execution_count":11,"id":"c259c402","metadata":{"id":"c259c402"},"outputs":[],"source":["from inverted_index_gcp import InvertedIndex"]},{"cell_type":"code","execution_count":12,"id":"f3ad8fea","metadata":{"id":"f3ad8fea","nbgrader":{"grade":false,"grade_id":"cell-token2bucket","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["import math\n","import statistics\n","bucket_name = 'ir_resources'\n","english_stopwords = frozenset(stopwords.words('english'))\n","corpus_stopwords = [\"category\", \"references\", \"also\", \"external\", \"links\", \n","                    \"may\", \"first\", \"see\", \"history\", \"people\", \"one\", \"two\", \n","                    \"part\", \"thumb\", \"including\", \"second\", \"following\", \n","                    \"many\", \"however\", \"would\", \"became\"]\n","\n","all_stopwords = english_stopwords.union(corpus_stopwords)\n","RE_WORD = re.compile(r\"\"\"[\\#\\@\\w](['\\-]?\\w){2,24}\"\"\", re.UNICODE)\n","\n","NUM_BUCKETS = 124\n","def token2bucket_id(token):\n","    return int(_hash(token),16) % NUM_BUCKETS\n","\n","# PLACE YOUR CODE HERE\n","def word_count(text, id):\n","    \n","    tokens = [token.group() for token in RE_WORD.finditer(text.lower())]\n","    map = {}\n","    for w in tokens:\n","        if w in all_stopwords:\n","            continue\n","        map[w] = map.get(w, 0) + 1\n","    return [(k,(id,v)) for k,v in map.items()]\n","\n","def reduce_word_counts(unsorted_pl):\n","    return sorted(unsorted_pl)\n","\n","def calculate_df(postings):\n","    return postings.map(lambda x:(x[0],len(x[1])))\n","\n","def partition_postings_and_write(postings,base_dir):   \n","    posting_lst_with_bucket = postings.map(lambda x:((token2bucket_id(x[0]),x)))\n","    posting_lst_group_by_bucket = posting_lst_with_bucket.groupByKey()\n","    return posting_lst_group_by_bucket.map(lambda x :InvertedIndex.write_a_posting_list(x,bucket_name,base_dir))\n","def calculate_dl(postings):\n","    return postings.map(lambda x:x[1]).flatMap(lambda x:x).reduceByKey(lambda x,y :x+y)\n","def calculate_tt(postings):\n","    return postings.map(lambda x: (x[0], np.sum([y[1] for y in x[1]])))\n","def calculate_nf(postings):\n","    return postings.map(lambda x: x[1]).flatMap(lambda x:x).map(lambda x:(x[0],x[1]**2)).groupByKey().mapValues(list).map(lambda x:(x[0],1/math.sqrt(np.sum(x[1]))))\n","def calculate_AVGDL(DL):\n","    return statistics.mean(DL.values())\n"]},{"cell_type":"markdown","id":"4c270076","metadata":{},"source":["# title inverted index"]},{"cell_type":"code","execution_count":13,"id":"649531c4","metadata":{"id":"cda39945"},"outputs":[],"source":["word_counts_title = doc_text_pairs_title.flatMap(lambda x: word_count(x[0], x[1]))"]},{"cell_type":"code","execution_count":14,"id":"67186500","metadata":{"id":"67186500"},"outputs":[],"source":["postings_title = word_counts_title.groupByKey().mapValues(reduce_word_counts)"]},{"cell_type":"code","execution_count":15,"id":"70835921","metadata":{"id":"70835921","outputId":"ccf99f27-6639-4fae-f3d0-2e5f5e9de6f9"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["w2df_title = calculate_df(postings_title).collectAsMap()"]},{"cell_type":"code","execution_count":16,"id":"eae0ceba","metadata":{"id":"eae0ceba"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["tt_title = calculate_tt(postings_title).collectAsMap()"]},{"cell_type":"code","execution_count":17,"id":"ad693571","metadata":{"id":"ad693571"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["DL_title = calculate_dl(postings_title).collectAsMap()"]},{"cell_type":"code","execution_count":18,"id":"c4151afa","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["nf_title = calculate_nf(postings_title).collectAsMap()"]},{"cell_type":"code","execution_count":19,"id":"f7cf51a4","metadata":{"id":"f7cf51a4"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["_ = partition_postings_and_write(postings_title,\"title_index\").collect()"]},{"cell_type":"code","execution_count":20,"id":"ab3296f4","metadata":{"id":"ab3296f4","nbgrader":{"grade":true,"grade_id":"collect-posting","locked":true,"points":0,"schema_version":3,"solution":false,"task":false}},"outputs":[],"source":["# collect all posting lists locations into one super-set\n","super_posting_locs_title = defaultdict(list)\n","for blob in client.list_blobs(bucket_name, prefix='title_index'):\n","    if not blob.name.endswith(\"pickle\"):\n","        continue\n","    with blob.open(\"rb\") as f:\n","        posting_locs_title = pickle.load(f)\n","        for k, v in posting_locs_title.items():\n","            super_posting_locs_title[k].extend(v)"]},{"cell_type":"markdown","id":"f6f66e3a","metadata":{"id":"f6f66e3a"},"source":["Putting it all together"]},{"cell_type":"code","execution_count":21,"id":"a5d2cfb6","metadata":{"id":"a5d2cfb6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Copying file://title_index.pkl [Content-Type=application/octet-stream]...\n","==> NOTE: You are uploading one or more large file(s), which would run          \n","significantly faster if you enable parallel composite uploads. This\n","feature can be enabled by editing the\n","\"parallel_composite_upload_threshold\" value in your .boto\n","configuration file. However, note that if you do this large files will\n","be uploaded as `composite objects\n","<https://cloud.google.com/storage/docs/composite-objects>`_,which\n","means that any user who downloads such objects will need to have a\n","compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n","without a compiled crcmod, computing checksums on composite objects is\n","so slow that gsutil disables downloads of composite objects.\n","\n","\\ [1 files][256.4 MiB/256.4 MiB]                                                \n","Operation completed over 1 objects/256.4 MiB.                                    \n"]}],"source":["# Create inverted index instance\n","inverted_title = InvertedIndex()\n","# Adding the posting locations dictionary to the inverted index\n","inverted_title.posting_locs = super_posting_locs_title\n","# Add the token - df dictionary to the inverted index\n","inverted_title.df = w2df_title\n","inverted_title.DL = DL_title\n","inverted_title.term_total = tt_title\n","inverted_title.nf = nf_title\n","inverted_title.AVGDL = calculate_AVGDL(DL_title)\n","\n","# write the global stats out\n","inverted_title.write_index('.', 'title_index')\n","\n","# upload to gs\n","index_src = \"title_index.pkl\"\n","index_dst = f'gs://{bucket_name}/title_index/{index_src}'\n","!gsutil cp $index_src $index_dst"]},{"cell_type":"code","execution_count":22,"id":"8f880d59","metadata":{"id":"8f880d59","nbgrader":{"grade":false,"grade_id":"cell-index_dst_size","locked":true,"schema_version":3,"solution":false,"task":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["256.38 MiB  2022-12-28T15:24:29Z  gs://ir_resources/title_index/title_index.pkl\r\n","TOTAL: 1 objects, 268831615 bytes (256.38 MiB)\r\n"]}],"source":["!gsutil ls -lh $index_dst"]},{"cell_type":"markdown","id":"2fa031fb","metadata":{},"source":["# body inverted index"]},{"cell_type":"code","execution_count":23,"id":"2a71a55e","metadata":{},"outputs":[],"source":["word_counts_body = doc_text_pairs_body.flatMap(lambda x: word_count(x[0], x[1]))"]},{"cell_type":"code","execution_count":24,"id":"6389ad86","metadata":{},"outputs":[],"source":["postings_body = word_counts_body.groupByKey().mapValues(reduce_word_counts)\n","postings_body_filtered = postings_body.filter(lambda x: len(x[1])>50)"]},{"cell_type":"code","execution_count":null,"id":"f0018b3d","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["w2df_body = calculate_df(postings_body_filtered).collectAsMap()"]},{"cell_type":"code","execution_count":null,"id":"738ab689","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["tt_body = calculate_tt(postings_body_filtered).collectAsMap()"]},{"cell_type":"code","execution_count":null,"id":"391e8018","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["DL_body = calculate_dl(postings_body_filtered).collectAsMap()"]},{"cell_type":"code","execution_count":null,"id":"3b34f310","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["nf_body = calculate_nf(postings_body_filtered).collectAsMap()"]},{"cell_type":"code","execution_count":null,"id":"b7f035b4","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["_ = partition_postings_and_write(postings_body_filtered,\"body_index\").collect()"]},{"cell_type":"code","execution_count":null,"id":"d19b362f","metadata":{},"outputs":[],"source":["# collect all posting lists locations into one super-set\n","super_posting_locs_body = defaultdict(list)\n","for blob in client.list_blobs(bucket_name, prefix='body_index'):\n","    if not blob.name.endswith(\"pickle\"):\n","        continue\n","    with blob.open(\"rb\") as f:\n","        posting_locs_body = pickle.load(f)\n","        for k, v in posting_locs_body.items():\n","            super_posting_locs_body[k].extend(v)"]},{"cell_type":"code","execution_count":null,"id":"dff6a12e","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Copying file://body_index.pkl [Content-Type=application/octet-stream]...\n","==> NOTE: You are uploading one or more large file(s), which would run          \n","significantly faster if you enable parallel composite uploads. This\n","feature can be enabled by editing the\n","\"parallel_composite_upload_threshold\" value in your .boto\n","configuration file. However, note that if you do this large files will\n","be uploaded as `composite objects\n","<https://cloud.google.com/storage/docs/composite-objects>`_,which\n","means that any user who downloads such objects will need to have a\n","compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n","without a compiled crcmod, computing checksums on composite objects is\n","so slow that gsutil disables downloads of composite objects.\n","\n","\\ [1 files][164.3 MiB/164.3 MiB]                                                \n","Operation completed over 1 objects/164.3 MiB.                                    \n"]}],"source":["# Create inverted index instance\n","inverted_body = InvertedIndex()\n","# Adding the posting locations dictionary to the inverted index\n","inverted_body.posting_locs = super_posting_locs_body\n","# Add the token - df dictionary to the inverted index\n","inverted_body.df = w2df_body\n","inverted_body.DL = DL_body\n","inverted_body.term_total = tt_body\n","inverted_body.nf = nf_body\n","inverted_body.AVGDL = calculate_AVGDL(DL_body)\n","\n","# write the global stats out\n","inverted_body.write_index('.', 'body_index')\n","\n","# upload to gs\n","index_src = \"body_index.pkl\"\n","index_dst = f'gs://{bucket_name}/body_index/{index_src}'\n","!gsutil cp $index_src $index_dst"]},{"cell_type":"code","execution_count":null,"id":"1b8cb604","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["164.29 MiB  2022-12-28T16:41:20Z  gs://ir_resources/body_index/body_index.pkl\r\n","TOTAL: 1 objects, 172271764 bytes (164.29 MiB)\r\n"]}],"source":["!gsutil ls -lh $index_dst"]},{"cell_type":"markdown","id":"15033c9e","metadata":{},"source":["# anchor inverted index"]},{"cell_type":"code","execution_count":38,"id":"b772f6c4","metadata":{},"outputs":[],"source":["doc_text_pairs_anchor = parquetFile.select(\"id\",\"anchor_text\").rdd\n","postings_doc_lst_titles = doc_text_pairs_anchor.map(lambda x:[(y[0], y[1]) for y in x[1]])\n","postings_doc_lst_titles = postings_doc_lst_titles.flatMap(lambda x:[(w ,id) for id,text in x for w in text.split()])\n","postings_term_to_docs = postings_doc_lst_titles.groupByKey().mapValues(set).map(lambda x:(x[0],[(doc_id ,1)for doc_id in x[1]]))\n"]},{"cell_type":"code","execution_count":null,"id":"066ab808","metadata":{},"outputs":[],"source":["_ = partition_postings_and_write(postings_term_to_docs,\"anchor_index\").collect()"]},{"cell_type":"code","execution_count":44,"id":"6b073270","metadata":{},"outputs":[],"source":["super_posting_locs_anchor = defaultdict(list)\n","for blob in client.list_blobs(bucket_name, prefix='anchor_index'):\n","    if not blob.name.endswith(\"pickle\"):\n","        continue\n","    with blob.open(\"rb\") as f:\n","        posting_locs_anchor = pickle.load(f)\n","        for k, v in posting_locs_anchor.items():\n","            super_posting_locs_anchor[k].extend(v)"]},{"cell_type":"code","execution_count":45,"id":"0d932e2b","metadata":{},"outputs":[],"source":["# Create inverted index instance\n","inverted_anchor = InvertedIndex()\n","# Adding the posting locations dictionary to the inverted index\n","inverted_anchor.posting_locs = super_posting_locs_anchor\n","\n","# write the global stats out\n","inverted_anchor.write_index('.', 'anchor_index')\n","\n","# upload to gs\n","index_src = \"anchor_index.pkl\"\n","index_dst = f'gs://{bucket_name}/anchor_index/{index_src}'"]},{"cell_type":"code","execution_count":46,"id":"c12f57ee","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Copying file://anchor_index.pkl [Content-Type=application/octet-stream]...\n","\\ [1 files][ 89.0 MiB/ 89.0 MiB]                                                \n","Operation completed over 1 objects/89.0 MiB.                                     \n"]}],"source":["!gsutil cp $index_src $index_dst"]},{"cell_type":"markdown","id":"7e77c778","metadata":{},"source":["# title to doc"]},{"cell_type":"code","execution_count":48,"id":"48037eef","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["docid_title_dict = parquetFile.select(\"id\",\"title\").rdd.collectAsMap()\n","with open(\"docid_title_dict.pkl\", 'wb') as f:\n","    pickle.dump(docid_title_dict, f)"]},{"cell_type":"code","execution_count":49,"id":"5e681eb5","metadata":{},"outputs":[],"source":["index_src = \"docid_title_dict.pkl\"\n","index_dst = f'gs://{bucket_name}/{index_src}'"]},{"cell_type":"code","execution_count":50,"id":"6ca9ed4d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Copying file://docid_title_dict.pkl [Content-Type=application/octet-stream]...\n","==> NOTE: You are uploading one or more large file(s), which would run          \n","significantly faster if you enable parallel composite uploads. This\n","feature can be enabled by editing the\n","\"parallel_composite_upload_threshold\" value in your .boto\n","configuration file. However, note that if you do this large files will\n","be uploaded as `composite objects\n","<https://cloud.google.com/storage/docs/composite-objects>`_,which\n","means that any user who downloads such objects will need to have a\n","compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n","without a compiled crcmod, computing checksums on composite objects is\n","so slow that gsutil disables downloads of composite objects.\n","\n","/ [1 files][168.9 MiB/168.9 MiB]                                                \n","Operation completed over 1 objects/168.9 MiB.                                    \n"]}],"source":["!gsutil cp $index_src $index_dst"]},{"cell_type":"code","execution_count":null,"id":"08e79c5f","metadata":{},"outputs":[],"source":[]}],"metadata":{"celltoolbar":"Create Assignment","colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"}},"nbformat":4,"nbformat_minor":5}